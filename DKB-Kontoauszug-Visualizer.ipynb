{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DKB Logo](https://upload.wikimedia.org/wikipedia/commons/d/d4/Deutsche_Kreditbank_AG_Logo_2016.svg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please set these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accountname = 'export' # set filename of the csv. e.g. \n",
    "\n",
    "# 0 or less means analyse all months\n",
    "number_of_last_months_to_analyse = 0 # 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv\n",
    "Works for DKB csv as of 2024-10-31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "csv_file= accountname+\".csv\"\n",
    "data = pd.read_csv(csv_file, index_col=\"Buchungsdatum\",\n",
    "                   header='infer', sep=';', quoting=1,\n",
    "                   parse_dates=True, date_format=\"%Y-%m-%d\",\n",
    "                   skiprows = 4, # ignore metadata which doesn't fit CSV rows format\n",
    "                   keep_default_na=False, # don't make empty values to become NaN\n",
    "                   encoding='utf-8', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Read metadata\n",
    "data = data.iloc[::-1] # reverse rows such that bookings are chronologically sorted\n",
    "\n",
    "with open(csv_file,\"r\",encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f,delimiter=\";\")\n",
    "    metadata = {}\n",
    "    for i, row in enumerate(reader):\n",
    "        if \"Kontostand\" in row[0]:\n",
    "            value = row[1]\n",
    "            value = value.replace(\".\",\"\").replace(\",\",\".\")[:-2] # '12.345,67\\xa0€' -> '12345.67'\n",
    "            end_balance = float(value)\n",
    "            break\n",
    "\n",
    "start_date = datetime.strptime( data.index[0] ,\"%d.%m.%y\").date()\n",
    "end_date = datetime.strptime( data.index[-1] ,\"%d.%m.%y\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"start:\",start_date)\n",
    "print(\"end:\",end_date)\n",
    "print(\"end balance:\",end_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party = \"Sender => Receiver\"\n",
    "sender = \"Zahlungspflichtige*r\"\n",
    "receiver = \"Zahlungsempfänger*in\"\n",
    "category = \"Kategorie\"\n",
    "amount = \"Betrag (€)\"\n",
    "cause = \"Verwendungszweck\"\n",
    "balance = \"Kontostand (EUR)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Fix US / EU decimal-point/comma\n",
    "data[amount] = data[amount].str.replace('.','')\n",
    "data[amount] = data[amount].str.replace(',','.')\n",
    "data[amount] = data[amount].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove small transactions to avoid noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[abs(data[amount]) > 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Dataframe to have first day first and filter by time-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "if number_of_last_months_to_analyse > 0:\n",
    "    start_date = end_date - relativedelta(months=number_of_last_months_to_analyse)\n",
    "\n",
    "# start_date may be not in the index, if there was no booking on that day. in that case, chose the next day which has any booking\n",
    "if str(start_date) not in data.index:\n",
    "    for dt_str in data.index:\n",
    "        dt = datetime.strptime( dt_str ,\"%d.%m.%y\").date()\n",
    "        if dt < start_date:\n",
    "            continue\n",
    "        start_date = dt\n",
    "        print(\"using new start date\", start_date, \"which is in the index.\")\n",
    "        break\n",
    "\n",
    "def dt2str(dt):\n",
    "    return dt.strftime(\"%d.%m.%y\")\n",
    "\n",
    "print(f\"Analysing time range: {start_date} -> {end_date}\")\n",
    "data = data.loc[dt2str(start_date):dt2str(end_date)]\n",
    "\n",
    "start_and_end_dates_string = \"(%i.%i.%i - %i.%i.%i)\" % (start_date.day, start_date.month, start_date.year, end_date.day, end_date.month, end_date.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fr = data.index[0]\n",
    "to = data.index[-1]\n",
    "print(fr,\"->\",to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute balance at each transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_balance = data[amount].sum().round(2)\n",
    "start_balance = end_balance - data_balance\n",
    "data[balance] = data[amount].cumsum()+start_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start\",start_balance)\n",
    "print(\"end\",end_balance)\n",
    "print(\"balance during csv timespan\",data_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data[balance].plot(\n",
    "    title='Account balance DKB %s' % accountname,\n",
    "    grid=True,\n",
    "    figsize=(20,8)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by transaction party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[party] = data[sender] + \" => \" + data[receiver]\n",
    "tx_party_group = data.groupby(party).agg({amount:\"sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_party_group = tx_party_group.sort_values(amount, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_party_length = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten name\n",
    "tx_party_group.index = [ \"=>\".join(map(lambda s: s[:shortened_party_length],str(idx).split(\"=>\"))) for idx in tx_party_group.index ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_party_group[amount].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tx_party_group[tx_party_group[amount].abs() > 50].plot.barh(\n",
    "    figsize=(10,60),\n",
    "    title=u'Aggregierte Zahlungen ab 50€ %s' % start_and_end_dates_string\n",
    "  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by Category\n",
    "We use some heuristics on the tranasaction details to put them into different categories.\n",
    "All transactions within a category will be aggregated for a better overall analysis.\n",
    "You may need to check the print output of the next cell and possibly adapt the mapping function for a better categorisation.\n",
    "\n",
    "**the text will be lower cased before categorisation**\n",
    "\n",
    "**Feel free to change these heuristic mappings - or adapt the code to map according to specififc transaction details.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"eat_out_or_get_food\": [\n",
    "        \"restaurant\",\n",
    "        \"gastro\",\n",
    "        \"dean david\",\n",
    "        \"cafe\",\n",
    "        \"baeckerei\",\n",
    "        \"coffee fellows\",\n",
    "        \"jim block\",\n",
    "        \"don qui\",\n",
    "        \"Osteria\",\n",
    "        \"subway\",\n",
    "        \"backhaus\",\n",
    "        \"burger king\",\n",
    "        \"campus suite\",\n",
    "        \"juice.more\",\n",
    "        \"Backerei\",\n",
    "        \"Avni Terhani\",\n",
    "        \"vegan\",\n",
    "        \"thai\",\n",
    "        \"indisch\",\n",
    "    ],\n",
    "    \"alltag_laden\": [\n",
    "        \"lidl\",\n",
    "        \"aldi\",\n",
    "        \"edeka\",\n",
    "        \"alnatura\",\n",
    "        \"rewe\",\n",
    "        \"vollcorner\",\n",
    "    ],\n",
    "    \"spezial_laden\": [\n",
    "        \"karstadt\",\n",
    "        \"galeria\",\n",
    "        \"kaufhof\",\n",
    "        \"mueller\",\n",
    "        \"migros\",\n",
    "        \"coop\",\n",
    "        \"dm fil\",\n",
    "        \"go asia\",\n",
    "        \"Drogerie\",\n",
    "        \"SUCKFUELL\",\n",
    "        \"butlers\",\n",
    "        \"Suckfull\",\n",
    "        \"Bio-Market\",\n",
    "        \"conrad m\",\n",
    "    ],\n",
    "    \"online_handel\":[\n",
    "        \"otto\",\n",
    "        \"conrad elec\",\n",
    "        \"amzn mktp\",\n",
    "        \"amazon\",\n",
    "    ],\n",
    "    \"transport\": [\n",
    "        \"FERNVERKEHR\",\n",
    "        \"flixbus\",\n",
    "        \"PAYPAL .DBVERTR\",\n",
    "    ],\n",
    "    \"ausflug\": [\n",
    "        \"hamburg\",\n",
    "        \"Hotel\",\n",
    "        \"PAYPAL .booking\",\n",
    "        \"prague\",\n",
    "        \"praha\",\n",
    "        \"Tubingen\",\n",
    "    ],\n",
    "    \"project\": [\n",
    "        \"openai\",\n",
    "        \"google.cloud\",\n",
    "        \"github\",\n",
    "    ],\n",
    "    \"freizeit\": [\n",
    "        \"VOLKSBAD\",\n",
    "        \"PAYPAL .SENNHEISER\",\n",
    "    ],\n",
    "    \"entertainment\": [\n",
    "        \"magellan\",\n",
    "        \"Amazon Prime\",\n",
    "        \"paypal .steam\",\n",
    "        \"netflix\"\n",
    "    ],\n",
    "    \"crypto\": [\n",
    "        \"bitflyer\",\n",
    "        \"coinbase\"\n",
    "    ],\n",
    "    \"health\": [\n",
    "        \"apotheke\",\n",
    "        \"Krankenversicherung\",\n",
    "    ],\n",
    "    \"cash\": [\n",
    "        \"bargeld\",\n",
    "        \"automat\",\n",
    "        \"cash\"\n",
    "    ],\n",
    "    \"dkb\": [\n",
    "        \"DKB\",\n",
    "        \"KREDITBANK\",\n",
    "    ],\n",
    "    \"miete\": [],\n",
    "    \"investment\": [],\n",
    "    \"emergency_fund\":[],\n",
    "    \"uncategorized\": [\n",
    "        \"PayPal (Europe)\",\n",
    "    ],\n",
    "    \"card_payment\": [],\n",
    "    \"minor\": [ # populated automatically\n",
    "    ]\n",
    "}\n",
    "\n",
    "def mapToCategory(x):\n",
    "    # use these transaction details to map to a category\n",
    "    p = x[party].lower()\n",
    "    c = x[cause].lower()\n",
    "    \n",
    "    # manual mappings\n",
    "    if \"WERTP. ABRECHN\".lower() in c or \"Depot \".lower() in c or \"WERTPAPIER\".lower() in c:\n",
    "        return \"investment\"\n",
    "    \n",
    "    if \"miete \".lower() in c:\n",
    "        return \"miete\"\n",
    "    \n",
    "    if \"KREDITKARTENABRECHNUNG\".lower() in c:\n",
    "        return \"card_payment\"\n",
    "    \n",
    "    # mappings by category\n",
    "    for cat, cat_words in categories.items():\n",
    "        if any(map(lambda r: r.lower() in p, cat_words)):\n",
    "            return cat\n",
    "    \n",
    "    # debitcard. may need adaptation\n",
    "    if \"Debitk.20 VISA Debit\".lower() in c:\n",
    "        return \"card_payment\"\n",
    "    \n",
    "    return p\n",
    "\n",
    "data[category] = data.apply(lambda x: mapToCategory(x), axis=1)\n",
    "\n",
    "print(len(data[category].unique()),\"categories\")\n",
    "\n",
    "print(\"============ uncategorized =================\")\n",
    "s = 0\n",
    "for x in data[category].unique():\n",
    "    ok = False\n",
    "    \n",
    "    for cat in categories.keys():\n",
    "        if x == cat:\n",
    "            ok = True\n",
    "\n",
    "    if not ok:\n",
    "        print(x)\n",
    "        idx = data[category] == x\n",
    "        s = s + abs(data[idx][amount].sum())\n",
    "        \n",
    "print(\"================================ sum of uncategorized: \",s) # todo. this doesn't seem to make sense ... 🤔"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breakdown by category. (Ignored transactions below 10€)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "byCategory = data.groupby(category).agg({amount:\"sum\"}).sort_values(amount,ascending=False)\n",
    "byCategory = byCategory[abs(byCategory[amount]) > 10]\n",
    "    \n",
    "\n",
    "costs = byCategory[byCategory[amount] < 0]\n",
    "costs.loc[:,amount] = -costs[amount]\n",
    "\n",
    "total_costs = costs[amount].sum()\n",
    "costs.plot.pie(\n",
    "    figsize=(12,12),\n",
    "    y=amount,\n",
    "    legend=None,\n",
    "    autopct=lambda x: str(round(x/100*total_costs)) + \"€ | \" + str(round(x)) + \"%\",\n",
    "    title=u'Nach Kategorie Aggregierte Kosten %s' % start_and_end_dates_string\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "byCategory[byCategory[amount] > 0].plot.pie(\n",
    "    figsize=(12,12),\n",
    "    y=amount,\n",
    "    legend=None,\n",
    "    title=u'Nach Kategorie Aggregiertes Einkommen %s' % start_and_end_dates_string\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "byCategory.plot.barh(\n",
    "    figsize=(6,40),\n",
    "    grid=True,\n",
    "    title=u'Nach Kategorie Aggregierte Zahlungen %s' % start_and_end_dates_string\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_category_analyse(cat,desc=party):\n",
    "    excursions = data[data[category] == cat].sort_values(amount,ascending=True)\n",
    "\n",
    "    excursions.plot.barh(\n",
    "        figsize=(12,12),\n",
    "        x=desc,\n",
    "        y=amount,\n",
    "        legend=None,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    return excursions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_category_analyse(\"investment\",desc=cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_category_analyse(\"dkb\", desc=cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_category_analyse(\"ausflug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_category_analyse(\"card_payment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_category_analyse(\"transport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
